---
layout: page
title: Keynote Speakers
permalink: /keynotes/
---
<div id="secondary" class="widget-area sidey" role="complementary">

      <ul class="xoxo">

          <li id="custom_html-3" class="widget_text widget-container widget_custom_html"><div class="textwidget custom-html-widget"><a class="twitter-timeline" data-width="300" data-height="600" data-theme="light" href="https://twitter.com/sefm_conf?ref_src=twsrc%5Etfw">Tweets by sefm2021</a> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div></li>	</ul>
</div>

<h2><a href="https://www-users.cs.york.ac.uk/~alcc/">Ana Cavalcanti</a>, University of York, UK</h2>

<h3><b><strong style="font-size:22px">RoboWorld: where can my robot work?</strong></b></h3>
<h3>Abstract</h3>
<p>The behaviour of a robot affects and is affected by its environment.  So, many of the expected and desirable properties of a robotic system depend on properties of its environment. While a complete model of that environment is very difficult, if not impossible, to construct, we can realistically capture assumptions about the environment.  In this talk, we present RoboWorld, a controlled natural language with a process-algebraic semantics that can be used to define (a) the operational requirements of a robot, and (b) how the
robot interacts with its environment.  RoboWorld is part of the RoboStar framework of domain-specific languages that support proof, simulation, and testing of robotic systems. RoboWorld plays a central role in all these forms of verification.</p>
<h3>Biography</h3>
<p>Ana Cavalcanti (University of York) is Professor of Software Verification and Royal Academy of Engineering Chair in Emerging Technologies working on Software Engineering for Robotics: modelling, validation, simulation, and testing. She currently leads the RoboStar research group at the University of York. She held a Royal Society-Wolfson Research Merit Award and a Royal Society Industry Fellowship to work with QinetiQ in avionics. She has chaired the Programme Committee of various well-established international conferences, is on the editorial board of four international journals, and is Chair of the board of the Formal Methods Europe Association. Her current research is on theory and practice of verification and
testing for robotics.</p>

<br>

<h2><a href="http://www.cs.toronto.edu/~chechik/">Marsha Chechik</a>, University of Toronto, Canada</h2>
<img src="{{ '/assets/chechik.png' | relative_url }}" />
<h3><b><strong style="font-size:22px">On Safety, Assurance and Reliability:  A Software Engineering Perspective</strong></b></h3>
<h3>Abstract</h3>
<p>From financial services platforms to social networks to vehicle control, software has come to mediate many activities of daily life. Governing bodies and standards organizations have responded to this trend by creating regulations and standards to address issues such as safety, security and privacy. In this environment, the compliance of software development to standards and regulations has emerged as a key requirement. Compliance claims and arguments are often captured in assurance cases, with linked evidence of compliance. Evidence can come from testcases, verification proofs, human judgement, or a combination of these. That is, we try to build (safety-critical) systems carefully according to well justified methods and articulate these justifications in an assurance case that is ultimately judged by a human.
Building safety arguments for traditional software systems is difficult ­­ they are lengthy and expensive to maintain, especially as software undergoes change. Safety is also notoriously non­compositional ­­ each subsystem might be safe but together they may create unsafe behaviors. It is also easy to miss cases, which in the simplest case would mean developing an argument for when a condition is true but missing arguing for a false condition. Furthermore, many ML­based systems are becoming safety­critical.  For example, recent Tesla self­driving cars misclassified emergency vehicles and caused multiple crashes. ML­based systems typically do not have precisely specified and machine­verifiable requirements. While some safety requirements can be stated clearly: "the system should detect all pedestrians at a crossing", these requirements are for the entire system, making them too high­level for safety analysis of individual components. Thus, systems with ML components (MLCs) add a significant layer of complexity for safety assurance.
I argue that safety assurance should be an integral part of building safe and reliable software systems, but this process needs support from advanced software engineering and software analysis. In this talk, I outline a few approaches for development of principled, tool-supported methodologies for creating and managing assurance arguments. I then describe recent work on specifying and verifying reliability requirements for machine-learned components in safety-critical domains.</p>
<h3>Biography</h3>
<p>Marsha Chechik is Professor and Chair in the Department of Computer Science at the University of Toronto. She received her Ph.D. from the University of Maryland in 1996. Prof. Chechik’s research interests are in the application of formal methods to improve the quality of software. She has authored over 200 papers in formal methods, software specification and verification, computer safety and security and requirements engineering.  Marsha Chechik has been Program Committee Co-Chair of the 2021 International Conference on Foundations of Software Engineering (ESEC/FSE’21), 2018 International Conference in Software Engineering (ICSE’18), 2016 International Conference on Tools and Algorithms for the Construction and Analysis of Systems (TACAS'16), the 2016 Working Conference on Verified Software: Theories, Tools, and Experiments (VSTTE16), the 2014 International Conference on Automated Software Engineering (ASE'14), the 2008 International Conference on Concurrency Theory (CONCUR'08), the 2008 International Conference on Computer Science and Software Engineering (CASCON'08), and the 2009 International Conference on Formal Aspects of Software Engineering (FASE'09). She is a Distinguished Member of ACM and Vice Chair of ACM SIGSOFT.</p>

<h2><a href="https://lafhis.dc.uba.ar/~suchitel">Sebastian Uchitel</a>, University of Buenos Aires, Argentina; and Imperial College London, UK</h2>
